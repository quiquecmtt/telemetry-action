name: Test Telemetry Action

on:
  # push:
  #   branches: [main]
  # pull_request:
  #   branches: [main]
  workflow_dispatch:

jobs:
  test-full-cpu:
    name: Test Full CPU Usage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Start Telemetry
        uses: ./
        with:
          sampling_interval: "1"
          output_format: "both"
          artifact_name: "full-cpu-metrics"

      - name: Max out all CPU cores
        run: |
          echo "Starting full CPU test..."

          python3 << 'EOF'
          import multiprocessing
          import time
          import os

          def cpu_burn():
              """Burn CPU indefinitely"""
              while True:
                  _ = sum(i*i for i in range(10000))

          # Get number of CPU cores
          cpu_count = multiprocessing.cpu_count()
          print(f"Detected {cpu_count} CPU cores")
          print(f"Starting {cpu_count} CPU workers to achieve 100% usage...")

          # Start a worker for each core
          procs = []
          for i in range(cpu_count):
              p = multiprocessing.Process(target=cpu_burn)
              p.start()
              procs.append(p)
              print(f"Started worker {i+1}/{cpu_count}")

          # Let it run for 30 seconds
          print("Running at 100% CPU for 60 seconds...")
          time.sleep(60)

          # Terminate all workers
          print("Stopping workers...")
          for p in procs:
              p.terminate()
              p.join()

          print("Full CPU test complete!")
          EOF

  test-full-memory:
    name: Test Full Memory Usage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Start Telemetry
        uses: ./
        with:
          sampling_interval: "1"
          output_format: "both"
          artifact_name: "full-memory-metrics"

      - name: Allocate maximum memory
        run: |
          echo "Starting full memory test..."

          python3 << 'EOF'
          import os
          import time

          # Get total system memory
          mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')
          mem_gb = mem_bytes / (1024**3)
          print(f"Total system memory: {mem_gb:.1f} GB")

          # Target 80% of total memory to avoid OOM killer
          target_percent = 0.80
          target_bytes = int(mem_bytes * target_percent)
          target_gb = target_bytes / (1024**3)
          print(f"Target allocation: {target_gb:.1f} GB ({target_percent*100:.0f}%)")

          # Allocate in 500MB chunks
          chunk_size = 500 * 1024 * 1024  # 500MB
          chunks = []
          allocated = 0

          print("Allocating memory...")
          try:
              while allocated < target_bytes:
                  chunk = bytearray(chunk_size)
                  # Touch the memory to ensure it's actually allocated
                  for i in range(0, len(chunk), 4096):
                      chunk[i] = 1
                  chunks.append(chunk)
                  allocated += chunk_size
                  print(f"Allocated: {allocated / (1024**3):.1f} GB")
                  time.sleep(0.5)
          except MemoryError:
              print("Hit memory limit!")

          print(f"Final allocation: {allocated / (1024**3):.1f} GB")
          print("Holding memory for 60 seconds...")
          time.sleep(60)

          print("Releasing memory...")
          chunks.clear()
          time.sleep(5)

          print("Full memory test complete!")
          EOF

  test-ramp:
    name: Test Ramp Up/Down
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Start Telemetry
        uses: ./
        with:
          sampling_interval: "1"
          output_format: "both"
          artifact_name: "ramp-metrics"

      - name: Ramp CPU and Memory
        run: |
          echo "Starting ramp test..."

          python3 << 'EOF'
          import multiprocessing
          import time
          import os

          def cpu_worker(duration):
              """Burn CPU for duration seconds"""
              end = time.time() + duration
              while time.time() < end:
                  _ = sum(i*i for i in range(10000))

          def start_cpu_workers(n, duration):
              """Start n CPU workers"""
              procs = []
              for _ in range(n):
                  p = multiprocessing.Process(target=cpu_worker, args=(duration,))
                  p.start()
                  procs.append(p)
              return procs

          # Memory storage
          memory_chunks = []

          print("=== Phase 1: Ramp UP ===")
          # Ramp up CPU: 1 -> 2 -> 3 -> 4 cores
          for cores in [1, 2, 3, 4]:
              print(f"CPU: {cores} cores active")
              procs = start_cpu_workers(cores, 8)

              # Also ramp memory: add 1000MB each step
              chunk = bytearray(1000 * 1024 * 1024)
              memory_chunks.append(chunk)
              print(f"Memory: {len(memory_chunks) * 1000}MB allocated")

              for p in procs:
                  p.join()

          print("=== Phase 2: Peak (hold) ===")
          print("Holding peak load for 20s...")
          procs = start_cpu_workers(4, 20)
          for p in procs:
              p.join()

          print("=== Phase 3: Ramp DOWN ===")
          # Ramp down CPU and release memory
          for cores in [3, 2, 1]:
              print(f"CPU: {cores} cores active")
              procs = start_cpu_workers(cores, 5)

              # Release memory
              if memory_chunks:
                  memory_chunks.pop()
                  print(f"Memory: {len(memory_chunks) * 1000}MB allocated")

              for p in procs:
                  p.join()

          print("=== Phase 4: Idle ===")
          memory_chunks.clear()
          print("All resources released, idling for 5s...")
          time.sleep(5)

          print("Ramp test complete!")
          EOF

  test-mixed-workload:
    name: Test Mixed Workload
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Start Telemetry
        uses: ./
        with:
          sampling_interval: "1"
          output_format: "both"
          artifact_name: "mixed-workload-metrics"

      - name: Run mixed CPU and Memory workload
        run: |
          echo "Starting mixed workload test..."

          # Phase 1: CPU spike
          echo "Phase 1: CPU spike (10s)"
          for i in {1..2}; do
            dd if=/dev/urandom bs=1M count=512 2>/dev/null | md5sum > /dev/null &
          done
          sleep 10

          # Phase 2: Memory allocation
          echo "Phase 2: Memory allocation"
          python3 -c "
          import time
          data = [bytearray(500 * 1024 * 1024) for _ in range(10)]  # 5GB
          print('Allocated 5GB')
          time.sleep(10)
          "

          # Phase 3: Combined
          echo "Phase 3: Combined CPU + Memory"
          python3 << 'EOF' &
          import time
          data = [bytearray(1000 * 1024 * 1024) for _ in range(5)]  # 5GB
          time.sleep(15)
          EOF

          for i in {1..2}; do
            dd if=/dev/urandom bs=1M count=512 2>/dev/null | md5sum > /dev/null &
          done
          sleep 15

          echo "Mixed workload test complete"
